{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jérémy TREMBLAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 : Supervied Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries that will be used in this notebook.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Import the pyplot module from matplotlib with the plt alias.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the sklearn modules.\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix seeds for reprodutiblity principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subfolder of this path, there is a dataset extracted from observations from the Bergen institute.\n",
    "The mission is to estimate the age of the fish based on the parameters provided in order to better regulate fish stocks.  \n",
    "\n",
    "Constraints:\n",
    "* Use the 3 models seen in class (regression, knn, decision tree)\n",
    "* Optimize your models by analyzing the different versions and possible parameterizations.  \n",
    "\n",
    "**The goal of this notebook is to realize the best possible model to predict data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step : load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the two CSV that will be used in this notebook with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  weight  length  liverweight  gonadweight  age\n",
      "0   1   20700   132.0        0.528        2.300   14\n",
      "1   2    1308    54.0        0.082        0.002    5\n",
      "2   3    2730    72.0        0.046        0.039    7\n",
      "3   4    3300    76.0        0.098        0.020    7\n",
      "4   5    1155    51.0        0.035        0.002    4\n",
      "---------------------------------------------------\n",
      "    id  weight  length  liverweight  gonadweight\n",
      "0  441    2566    70.0        0.077        0.005\n",
      "1  442    1235    53.0        0.035        0.006\n",
      "2  443    4008    82.0        0.114        0.146\n",
      "3  444    4310    78.0        0.318        0.370\n",
      "4  445   16130   105.0        1.118        3.720\n"
     ]
    }
   ],
   "source": [
    "# Specify the relative path of the the files.\n",
    "train_file_path = 'datasets/train.csv'\n",
    "test_file_path = 'datasets/test.csv'\n",
    "\n",
    "# Load the database into a DataFrame.\n",
    "df_train = pd.read_csv(train_file_path)\n",
    "df_test = pd.read_csv(test_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame with head.\n",
    "print(df_train.head())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. We will now explore data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             False\n",
      "weight         False\n",
      "length         False\n",
      "liverweight    False\n",
      "gonadweight    False\n",
      "age            False\n",
      "dtype: bool\n",
      "id             False\n",
      "weight         False\n",
      "length         False\n",
      "liverweight    False\n",
      "gonadweight    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().any())\n",
    "print(df_test.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are already clean, we can easily read it now and search some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 6)\n",
      "(81, 5)\n"
     ]
    }
   ],
   "source": [
    "# Know the dimensions of the dataframes.\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 440 rows and 6 columns for the train dataset and 81 rows and 5 columns for the test dataset, let's check the content more in detail with some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440 entries, 0 to 439\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           440 non-null    int64  \n",
      " 1   weight       440 non-null    int64  \n",
      " 2   length       440 non-null    float64\n",
      " 3   liverweight  440 non-null    float64\n",
      " 4   gonadweight  440 non-null    float64\n",
      " 5   age          440 non-null    int64  \n",
      "dtypes: float64(3), int64(3)\n",
      "memory usage: 20.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Display usefull information about the train dataset.\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81 entries, 0 to 80\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           81 non-null     int64  \n",
      " 1   weight       81 non-null     int64  \n",
      " 2   length       81 non-null     float64\n",
      " 3   liverweight  81 non-null     float64\n",
      " 4   gonadweight  81 non-null     float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 3.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Display usefull information about the test dataset.\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>length</th>\n",
       "      <th>liverweight</th>\n",
       "      <th>gonadweight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>220.500000</td>\n",
       "      <td>5134.756818</td>\n",
       "      <td>76.900000</td>\n",
       "      <td>0.325775</td>\n",
       "      <td>0.472077</td>\n",
       "      <td>7.745455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>127.161315</td>\n",
       "      <td>4296.584819</td>\n",
       "      <td>19.683868</td>\n",
       "      <td>0.366086</td>\n",
       "      <td>0.821960</td>\n",
       "      <td>2.637340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>110.750000</td>\n",
       "      <td>2210.500000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>220.500000</td>\n",
       "      <td>3715.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>330.250000</td>\n",
       "      <td>6808.750000</td>\n",
       "      <td>90.250000</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>440.000000</td>\n",
       "      <td>23620.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1.823000</td>\n",
       "      <td>5.240000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        weight      length  liverweight  gonadweight  \\\n",
       "count  440.000000    440.000000  440.000000   440.000000   440.000000   \n",
       "mean   220.500000   5134.756818   76.900000     0.325775     0.472077   \n",
       "std    127.161315   4296.584819   19.683868     0.366086     0.821960   \n",
       "min      1.000000    495.000000   40.000000     0.007000     0.001000   \n",
       "25%    110.750000   2210.500000   63.000000     0.073500     0.010000   \n",
       "50%    220.500000   3715.000000   75.000000     0.180500     0.092500   \n",
       "75%    330.250000   6808.750000   90.250000     0.457500     0.483000   \n",
       "max    440.000000  23620.000000  132.000000     1.823000     5.240000   \n",
       "\n",
       "              age  \n",
       "count  440.000000  \n",
       "mean     7.745455  \n",
       "std      2.637340  \n",
       "min      3.000000  \n",
       "25%      6.000000  \n",
       "50%      7.000000  \n",
       "75%      9.000000  \n",
       "max     16.000000  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>length</th>\n",
       "      <th>liverweight</th>\n",
       "      <th>gonadweight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>481.000000</td>\n",
       "      <td>4527.728395</td>\n",
       "      <td>73.981481</td>\n",
       "      <td>0.309037</td>\n",
       "      <td>0.445222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.526581</td>\n",
       "      <td>4029.039696</td>\n",
       "      <td>19.954706</td>\n",
       "      <td>0.397947</td>\n",
       "      <td>0.838763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>441.000000</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>461.000000</td>\n",
       "      <td>1706.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>481.000000</td>\n",
       "      <td>3290.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.147000</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>6320.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>521.000000</td>\n",
       "      <td>17110.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>4.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        weight      length  liverweight  gonadweight\n",
       "count   81.000000     81.000000   81.000000    81.000000    81.000000\n",
       "mean   481.000000   4527.728395   73.981481     0.309037     0.445222\n",
       "std     23.526581   4029.039696   19.954706     0.397947     0.838763\n",
       "min    441.000000    550.000000   40.500000     0.012000     0.001000\n",
       "25%    461.000000   1706.000000   58.000000     0.077000     0.006000\n",
       "50%    481.000000   3290.000000   73.000000     0.147000     0.106000\n",
       "75%    501.000000   6320.000000   86.000000     0.318000     0.398000\n",
       "max    521.000000  17110.000000  124.000000     1.680000     4.010000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to predict the age of the fish, we will use the columns `weight`, `length`, `liverweight` and `gonadweight`.\n",
    "The `id` is here just to identify the fish. The `age` is the variable we want to know. This is why the column does not exists in the test dataset. Let's check the number of fish with their ages for the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "7     75\n",
       "6     70\n",
       "8     63\n",
       "9     51\n",
       "5     47\n",
       "4     34\n",
       "12    30\n",
       "11    23\n",
       "10    18\n",
       "13    10\n",
       "14     9\n",
       "3      6\n",
       "15     2\n",
       "16     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to work with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step : clean and separate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must use our train dataset and split it to use it to train and test our model and check his performances. The test dataset cannot be used ffor that because it contains the data we want to predict, and we cannot check the effiency of the mdoel with it. We do not need to clean the dataset as saw at the previous step, so let's suppress the `id` and `age` columns of the datasets because they will not be used by our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real = df_train[df_train.columns.difference([\"id\", \"age\"])] # The columns used to predict the fish's age.\n",
    "y_train_real = df_train.age # The answer.\n",
    "X_test_real = df_test[df_test.columns.difference([\"id\"])] # The columns used to predict the fish's age in the test dataset.\n",
    "\n",
    "# Let's split data: 30% for test and 70% for train.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_real, y_train_real, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use it with our models. We are in a regression case. We will use a LinearRegressor, a KNNRegressor and a DecisionTreeRegressor. For each model, we will try different value for some parameters to see which one produces the best results and at the end of each step, we will apply our model on our test dataset and submit our work for these predictions. These prediction files can be found under the `predictions` folder. So first, let's use the LinearRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thrid step : using Linear Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reshape our data and then create our model, fit it and see his predictions about our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data size (not usefull here).\n",
    "X_test_reshaped = np.array(X_test).reshape(-1, 1)\n",
    "y_test_reshaped = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression, fit it and get its results and predictions.\n",
    "linear = LinearRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "# First let's see how our model predict the test data\n",
    "y_predict = linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check some metrics now to see the performances of our model. For this, we will use the R2 score with the mean square error along this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2): 0.7922446301406176\n",
      "Mean Squared Error (MSE): 1.5684194990417326\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared (R2).\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE).\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "\n",
    "# Display the results\n",
    "print(f'R-squared (R2): {r2}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we seek to have an R2 as close to 1 as possible (better performance) and an MSE as low as possible (more accurate predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve again the values, we can search a parameter and try different value to improve our results. Because this is not one of the best model use for that generally, we will not parameterize this model. We will therefore parameterize the others. So we are now done with this model, let's predict the results of our test dataset and save it in a CSV file. We wiil need to train our model on all data and our train file to imrpove again our model before predicting the new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "linear.fit(X_train_real, y_train_real)\n",
    "\n",
    "# Predict our test dataset.\n",
    "y_predict = linear.predict(X_test_real)\n",
    "\n",
    "# Create a dataframe to associate the fish id with its prediction.\n",
    "predictions_df = pd.DataFrame({'id': df_test['id'], 'age': y_predict})\n",
    "\n",
    "# Save data into a CSV file to submit it on Kaggle.\n",
    "predictions_df.to_csv('predictions/linear_regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have submitted our file we can continue with the next model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth step : using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T>he process is the same as before, but we will use a KNN Regressor for that. As previsou, let's create our model, train it and predict result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: R-squared = 0.7265, MAE = 1.12, MSE = 2.06\n"
     ]
    }
   ],
   "source": [
    "# Create a K-Nearest Neighbors (KNN) model with no parameter (for now).\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the coefficient of determination (R-squared).\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE).\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE).\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Display the metrics for each n_neighbors value.\n",
    "print(f'KNN: R-squared = {r2:.4f}, MAE = {mae:.2f}, MSE = {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we seek to have an R2 as close to 1 as possible (better performance), an MSE as low as possible (more accurate predictions) and a MAE as low as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a bad score but we could probably improve it if we set a parameter `n_neighbor` with a good value. To determine this value, we will loop and test different values and see after the predicted results which one is the best generalisation for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 1: R-squared = 0.6076, MAE = 1.28, MSE = 2.96\n",
      "n_neighbors = 2: R-squared = 0.6678, MAE = 1.23, MSE = 2.51\n",
      "n_neighbors = 3: R-squared = 0.6996, MAE = 1.15, MSE = 2.27\n",
      "n_neighbors = 4: R-squared = 0.7173, MAE = 1.13, MSE = 2.13\n",
      "n_neighbors = 5: R-squared = 0.7265, MAE = 1.12, MSE = 2.06\n",
      "n_neighbors = 6: R-squared = 0.7362, MAE = 1.12, MSE = 1.99\n",
      "n_neighbors = 7: R-squared = 0.7437, MAE = 1.09, MSE = 1.93\n",
      "n_neighbors = 8: R-squared = 0.7423, MAE = 1.10, MSE = 1.95\n",
      "n_neighbors = 9: R-squared = 0.7421, MAE = 1.09, MSE = 1.95\n",
      "n_neighbors = 10: R-squared = 0.7508, MAE = 1.08, MSE = 1.88\n",
      "n_neighbors = 11: R-squared = 0.7570, MAE = 1.06, MSE = 1.83\n",
      "n_neighbors = 12: R-squared = 0.7638, MAE = 1.05, MSE = 1.78\n",
      "n_neighbors = 13: R-squared = 0.7713, MAE = 1.02, MSE = 1.73\n",
      "n_neighbors = 14: R-squared = 0.7688, MAE = 1.02, MSE = 1.75\n",
      "n_neighbors = 15: R-squared = 0.7724, MAE = 1.01, MSE = 1.72\n",
      "n_neighbors = 16: R-squared = 0.7756, MAE = 1.00, MSE = 1.69\n",
      "n_neighbors = 17: R-squared = 0.7775, MAE = 1.00, MSE = 1.68\n",
      "n_neighbors = 18: R-squared = 0.7773, MAE = 1.01, MSE = 1.68\n",
      "n_neighbors = 19: R-squared = 0.7756, MAE = 1.01, MSE = 1.69\n",
      "n_neighbors = 20: R-squared = 0.7786, MAE = 1.00, MSE = 1.67\n",
      "n_neighbors = 21: R-squared = 0.7776, MAE = 1.00, MSE = 1.68\n",
      "n_neighbors = 22: R-squared = 0.7756, MAE = 1.01, MSE = 1.69\n",
      "n_neighbors = 23: R-squared = 0.7765, MAE = 1.00, MSE = 1.69\n",
      "n_neighbors = 24: R-squared = 0.7771, MAE = 1.00, MSE = 1.68\n",
      "n_neighbors = 25: R-squared = 0.7787, MAE = 0.99, MSE = 1.67\n",
      "n_neighbors = 26: R-squared = 0.7798, MAE = 0.99, MSE = 1.66\n",
      "n_neighbors = 27: R-squared = 0.7771, MAE = 1.00, MSE = 1.68\n",
      "n_neighbors = 28: R-squared = 0.7767, MAE = 1.00, MSE = 1.69\n",
      "n_neighbors = 29: R-squared = 0.7762, MAE = 1.00, MSE = 1.69\n",
      "n_neighbors = 30: R-squared = 0.7750, MAE = 1.00, MSE = 1.70\n",
      "n_neighbors = 31: R-squared = 0.7755, MAE = 0.99, MSE = 1.69\n",
      "n_neighbors = 32: R-squared = 0.7752, MAE = 1.00, MSE = 1.70\n",
      "n_neighbors = 33: R-squared = 0.7747, MAE = 1.00, MSE = 1.70\n",
      "n_neighbors = 34: R-squared = 0.7711, MAE = 1.00, MSE = 1.73\n",
      "n_neighbors = 35: R-squared = 0.7690, MAE = 1.01, MSE = 1.74\n",
      "n_neighbors = 36: R-squared = 0.7684, MAE = 1.01, MSE = 1.75\n",
      "n_neighbors = 37: R-squared = 0.7679, MAE = 1.01, MSE = 1.75\n",
      "n_neighbors = 38: R-squared = 0.7669, MAE = 1.01, MSE = 1.76\n",
      "n_neighbors = 39: R-squared = 0.7682, MAE = 1.01, MSE = 1.75\n",
      "n_neighbors = 40: R-squared = 0.7676, MAE = 1.01, MSE = 1.75\n"
     ]
    }
   ],
   "source": [
    "# List of n_neighbors values to test.\n",
    "n_neighbors_values = list(range(1, 41))  # From 1 to 41 inclusive.\n",
    "\n",
    "# Do the same as before but with a paremeter and a loop...\n",
    "for n_neighbors in n_neighbors_values:\n",
    "    # Create a K-Nearest Neighbors (KNN) model with the current n_neighbors value.\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set.\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the coefficient of determination (R-squared).\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate the Mean Absolute Error (MAE).\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Calculate the Mean Squared Error (MSE).\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Display the metrics for each n_neighbors value.\n",
    "    print(f'n_neighbors = {n_neighbors}: R-squared = {r2:.4f}, MAE = {mae:.2f}, MSE = {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In choosing the optimal value for n_neighbors, a trade-off needs to be considered. While a larger number of neighbors improves the fit (higher R-squared) and reduces prediction errors (lower MAE and MSE), it may lead to over-smoothing and loss of sensitivity to local patterns in the data.\n",
    "\n",
    "Considering the trade-off, we may want to choose a value that provides a good balance between model complexity and performance. In this case, a value around 25 to 30 seems to offer a good balance, as it provides a high R-squared, low MAE, and low MSE. The best choice is probably 26 with the best values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seems smart to use a Standard Scaler to normalize the data and improve our model performance again. We will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler.\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we should transform our data by using our scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train our model and predict the value based on the parameter found just before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 8: R-squared = 0.7656, MAE = 1.00, MSE = 1.77\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_neighbors=26)  # We choose an appropriate n_neighbors value which is 26.\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)  # Predict.\n",
    "\n",
    "# Compute values.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Display data.\n",
    "print(f'n_neighbors = 8: R-squared = {r2:.4f}, MAE = {mae:.2f}, MSE = {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have improve our model with better results. We will do another turn as previous to see if there is a better value for our parameter `n_neighbors` now we have normalized our data with a Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 1: R-squared = 0.6568, MAE = 1.17, MSE = 2.59\n",
      "n_neighbors = 2: R-squared = 0.7286, MAE = 1.08, MSE = 2.05\n",
      "n_neighbors = 3: R-squared = 0.7453, MAE = 1.02, MSE = 1.92\n",
      "n_neighbors = 4: R-squared = 0.7493, MAE = 1.04, MSE = 1.89\n",
      "n_neighbors = 5: R-squared = 0.7480, MAE = 1.05, MSE = 1.90\n",
      "n_neighbors = 6: R-squared = 0.7707, MAE = 1.01, MSE = 1.73\n",
      "n_neighbors = 7: R-squared = 0.7763, MAE = 0.99, MSE = 1.69\n",
      "n_neighbors = 8: R-squared = 0.7773, MAE = 0.99, MSE = 1.68\n",
      "n_neighbors = 9: R-squared = 0.7800, MAE = 0.99, MSE = 1.66\n",
      "n_neighbors = 10: R-squared = 0.7758, MAE = 1.00, MSE = 1.69\n",
      "n_neighbors = 11: R-squared = 0.7720, MAE = 1.01, MSE = 1.72\n",
      "n_neighbors = 12: R-squared = 0.7711, MAE = 1.01, MSE = 1.73\n",
      "n_neighbors = 13: R-squared = 0.7672, MAE = 1.01, MSE = 1.76\n",
      "n_neighbors = 14: R-squared = 0.7684, MAE = 1.00, MSE = 1.75\n",
      "n_neighbors = 15: R-squared = 0.7642, MAE = 1.01, MSE = 1.78\n",
      "n_neighbors = 16: R-squared = 0.7669, MAE = 1.00, MSE = 1.76\n",
      "n_neighbors = 17: R-squared = 0.7692, MAE = 1.00, MSE = 1.74\n",
      "n_neighbors = 18: R-squared = 0.7728, MAE = 0.99, MSE = 1.71\n",
      "n_neighbors = 19: R-squared = 0.7709, MAE = 1.00, MSE = 1.73\n",
      "n_neighbors = 20: R-squared = 0.7746, MAE = 1.00, MSE = 1.70\n",
      "n_neighbors = 21: R-squared = 0.7729, MAE = 1.00, MSE = 1.71\n",
      "n_neighbors = 22: R-squared = 0.7722, MAE = 0.99, MSE = 1.72\n",
      "n_neighbors = 23: R-squared = 0.7701, MAE = 0.99, MSE = 1.74\n",
      "n_neighbors = 24: R-squared = 0.7691, MAE = 1.00, MSE = 1.74\n",
      "n_neighbors = 25: R-squared = 0.7661, MAE = 1.00, MSE = 1.77\n",
      "n_neighbors = 26: R-squared = 0.7656, MAE = 1.00, MSE = 1.77\n",
      "n_neighbors = 27: R-squared = 0.7637, MAE = 1.00, MSE = 1.78\n",
      "n_neighbors = 28: R-squared = 0.7657, MAE = 1.00, MSE = 1.77\n",
      "n_neighbors = 29: R-squared = 0.7658, MAE = 0.99, MSE = 1.77\n",
      "n_neighbors = 30: R-squared = 0.7674, MAE = 0.99, MSE = 1.76\n",
      "n_neighbors = 31: R-squared = 0.7648, MAE = 1.00, MSE = 1.78\n",
      "n_neighbors = 32: R-squared = 0.7643, MAE = 1.00, MSE = 1.78\n",
      "n_neighbors = 33: R-squared = 0.7597, MAE = 1.01, MSE = 1.81\n",
      "n_neighbors = 34: R-squared = 0.7598, MAE = 1.00, MSE = 1.81\n",
      "n_neighbors = 35: R-squared = 0.7575, MAE = 1.00, MSE = 1.83\n",
      "n_neighbors = 36: R-squared = 0.7555, MAE = 1.00, MSE = 1.85\n",
      "n_neighbors = 37: R-squared = 0.7545, MAE = 1.01, MSE = 1.85\n",
      "n_neighbors = 38: R-squared = 0.7545, MAE = 1.01, MSE = 1.85\n",
      "n_neighbors = 39: R-squared = 0.7531, MAE = 1.01, MSE = 1.86\n",
      "n_neighbors = 40: R-squared = 0.7528, MAE = 1.01, MSE = 1.87\n"
     ]
    }
   ],
   "source": [
    "# Same as previous but with scaled data...\n",
    "n_neighbors_values = list(range(1, 41))\n",
    "\n",
    "for n_neighbors in n_neighbors_values:\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print(f'n_neighbors = {n_neighbors}: R-squared = {r2:.4f}, MAE = {mae:.2f}, MSE = {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a value between 25 and 30 seems to be good base on the R2 valeu, the MSE and the MAE. We will keep 26. Let's now use our model to predict our test data and save it into a file as previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model, scale data, fit and predict and all train data.\n",
    "knn = KNeighborsRegressor(n_neighbors=26)\n",
    "X_train_real_scaled = scaler.fit_transform(X_train_real)\n",
    "X_test_real_scaled = scaler.transform(X_test_real)\n",
    "knn.fit(X_train_real_scaled, y_train_real)\n",
    "y_predict = knn.predict(X_test_real_scaled)\n",
    "\n",
    "# Save results.\n",
    "predictions_df = pd.DataFrame({'id': df_test['id'], 'age': y_predict})\n",
    "predictions_df.to_csv('predictions/knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth step : using a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will finally use a DecisionTreeRegressor to predict data. As before, we first create our model to see the indicators withour applying parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTR: [MSE: 2.46, MAE: 1.14, R2: 0.67]\n"
     ]
    }
   ],
   "source": [
    "# Create the model and train it.\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Compute MSE, MAE and R2 and display data.\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "mae = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "print(f\"DTR: [MSE: {mse:.2f}, MAE: {mae:.2f}, R2: {r2:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we are going to try to improve these indicators by searching a good value for the depth parameter of the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (depth=1): [MSE: 3.63, MAE: 1.50, R2: 0.52]\n",
      "Model (depth=2): [MSE: 1.80, MAE: 1.03, R2: 0.76]\n",
      "Model (depth=3): [MSE: 1.65, MAE: 0.99, R2: 0.78]\n",
      "Model (depth=4): [MSE: 1.65, MAE: 1.00, R2: 0.78]\n",
      "Model (depth=5): [MSE: 1.61, MAE: 0.96, R2: 0.79]\n",
      "Model (depth=6): [MSE: 1.82, MAE: 1.01, R2: 0.76]\n",
      "Model (depth=7): [MSE: 1.83, MAE: 1.01, R2: 0.76]\n",
      "Model (depth=8): [MSE: 1.98, MAE: 1.05, R2: 0.74]\n",
      "Model (depth=9): [MSE: 2.14, MAE: 1.08, R2: 0.72]\n",
      "Model (depth=10): [MSE: 2.18, MAE: 1.08, R2: 0.71]\n",
      "Model (depth=11): [MSE: 2.39, MAE: 1.13, R2: 0.68]\n",
      "Model (depth=12): [MSE: 2.32, MAE: 1.11, R2: 0.69]\n",
      "Model (depth=13): [MSE: 2.34, MAE: 1.11, R2: 0.69]\n",
      "Model (depth=14): [MSE: 2.22, MAE: 1.08, R2: 0.71]\n",
      "Model (depth=15): [MSE: 2.41, MAE: 1.15, R2: 0.68]\n",
      "Model (depth=16): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=17): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=18): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=19): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=20): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=21): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=22): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=23): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=24): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=25): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=26): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=27): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=28): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=29): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=30): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=31): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=32): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=33): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=34): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=35): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=36): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=37): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=38): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=39): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n",
      "Model (depth=40): [MSE: 2.46, MAE: 1.14, R2: 0.67]\n"
     ]
    }
   ],
   "source": [
    "# We test the first 41 depth.\n",
    "depths = range(1, 41)\n",
    "\n",
    "# Iterate through each depth and create a regression tree, train it and predict result, compare the prediction and display the accuracy.\n",
    "for depth in depths:\n",
    "    model = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    # Compute MSE, MAE and R2 and display data.\n",
    "    mse = mean_squared_error(y_test, y_predict)\n",
    "    mae = mean_absolute_error(y_test, y_predict)\n",
    "    r2 = r2_score(y_test, y_predict)\n",
    "    print(f\"Model (depth={depth}): [MSE: {mse:.2f}, MAE: {mae:.2f}, R2: {r2:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have the best performances for a depth between 3 and 5, based on the indicators. We will choose the middle value, 4, for the next parts.\n",
    "We are going to train our final model with all the value as usual and predict the value of our test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and train it.\n",
    "dtr = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "dtr.fit(X_train_real, y_train_real)\n",
    "y_predict = dtr.predict(X_test_real)\n",
    "\n",
    "# Save results.\n",
    "predictions_df = pd.DataFrame({'id': df_test['id'], 'age': y_predict})\n",
    "predictions_df.to_csv('predictions/decision_tree_regressor.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
