{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jérémy TREMBLAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: The Simpsons Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jtrem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import used in this notebook.\n",
    "import os\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Dropout, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix seeds for reprodutiblity principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subfolder of this path, there is a dataset extracted from The Simpsons serie.\n",
    "The mission is to classify correctly each person for each image to the corresponding personnage. This dataset is composed of more than 6000 images for training and nearly 600 for testing. Each image is associated with a class. The dataset offers 18 different classes, i.e. 18 different characters from The Simpsons.\n",
    "\n",
    "Constraints:\n",
    "* Don't cheat!\n",
    "* Respect a model with at most 1M parameters (it will be checked)\n",
    "* Max dataset image size must be (64, 64)\n",
    "\n",
    "**The goal of this notebook is to realize the best possible model to predict data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step : load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load the two CSV that will be used in this notebook with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   width  height          className  classId                path\n",
      "0    236     333       bart_simpson        2  dataset_000000.png\n",
      "1    154     223       nelson_muntz       15  dataset_000001.png\n",
      "2    187     294      kent_brockman        8  dataset_000002.png\n",
      "3    219     281       ned_flanders       14  dataset_000003.png\n",
      "4    278     384  principal_skinner       16  dataset_000004.png\n",
      "---------------------------------------------------\n",
      "   width  height             path\n",
      "0    194     328  test_000000.png\n",
      "1    236     363  test_000001.png\n",
      "2    185     373  test_000002.png\n",
      "3    380     399  test_000003.png\n",
      "4    152     294  test_000004.png\n"
     ]
    }
   ],
   "source": [
    "# Specify the relative path of the the files.\n",
    "train_file_path = 'datasets/train.csv'\n",
    "test_file_path = 'datasets/test.csv'\n",
    "\n",
    "# Load the database into a DataFrame.\n",
    "df_train = pd.read_csv(train_file_path)\n",
    "df_test = pd.read_csv(test_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame with head.\n",
    "print(df_train.head())\n",
    "print(\"---------------------------------------------------\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. We will now explore data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width        False\n",
      "height       False\n",
      "className    False\n",
      "classId      False\n",
      "path         False\n",
      "dtype: bool\n",
      "width     False\n",
      "height    False\n",
      "path      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().any())\n",
    "print(df_test.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are already clean, we can easily read it now and search some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5458, 5)\n",
      "(596, 3)\n"
     ]
    }
   ],
   "source": [
    "# Know the dimensions of the dataframes.\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 5458 rows and 5 columns for the train dataset and 596 rows and 3 columns for the test dataset, let's check the content more in detail with some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5458 entries, 0 to 5457\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   width      5458 non-null   int64 \n",
      " 1   height     5458 non-null   int64 \n",
      " 2   className  5458 non-null   object\n",
      " 3   classId    5458 non-null   int64 \n",
      " 4   path       5458 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 213.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display usefull information about the train dataset.\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 596 entries, 0 to 595\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   width   596 non-null    int64 \n",
      " 1   height  596 non-null    int64 \n",
      " 2   path    596 non-null    object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display usefull information about the test dataset.\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>classId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5458.000000</td>\n",
       "      <td>5458.000000</td>\n",
       "      <td>5458.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>226.390253</td>\n",
       "      <td>312.764749</td>\n",
       "      <td>8.030781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73.223297</td>\n",
       "      <td>82.585173</td>\n",
       "      <td>5.278480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>111.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>214.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>264.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>629.000000</td>\n",
       "      <td>618.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             width       height      classId\n",
       "count  5458.000000  5458.000000  5458.000000\n",
       "mean    226.390253   312.764749     8.030781\n",
       "std      73.223297    82.585173     5.278480\n",
       "min     111.000000   114.000000     0.000000\n",
       "25%     173.000000   252.000000     3.000000\n",
       "50%     214.000000   317.000000     8.000000\n",
       "75%     264.000000   373.000000    13.000000\n",
       "max     629.000000   618.000000    17.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>228.652685</td>\n",
       "      <td>315.07047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79.461392</td>\n",
       "      <td>85.25644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>130.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>173.750000</td>\n",
       "      <td>253.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>319.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>269.250000</td>\n",
       "      <td>380.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>816.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            width     height\n",
       "count  596.000000  596.00000\n",
       "mean   228.652685  315.07047\n",
       "std     79.461392   85.25644\n",
       "min    112.000000  130.00000\n",
       "25%    173.750000  253.00000\n",
       "50%    210.000000  319.00000\n",
       "75%    269.250000  380.00000\n",
       "max    800.000000  816.00000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to predict the class of the simpson, we will use the columns `path` which contains the path to the image of the simpson. The dataset also provides the width and length of the images and the `className` containing the name of the personnage and its associated `classId`. For the test dataset, we also have the size of the image and their paths, but not their classes because it is what we want to know.\n",
    "Let's check the number of simpsonfor each class in the train dataset to see if the data is well balanced between the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "className\n",
       "homer_simpson               533\n",
       "abraham_grampa_simpson      512\n",
       "marge_simpson               491\n",
       "bart_simpson                485\n",
       "ned_flanders                483\n",
       "charles_montgomery_burns    461\n",
       "lisa_simpson                420\n",
       "principal_skinner           407\n",
       "nelson_muntz                186\n",
       "krusty_the_clown            186\n",
       "chief_wiggum                181\n",
       "kent_brockman               168\n",
       "apu_nahasapeemapetilon      166\n",
       "edna_krabappel              164\n",
       "moe_szyslak                 164\n",
       "milhouse_van_houten         164\n",
       "comic_book_guy              149\n",
       "sideshow_bob                138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.className.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is not balanced between the classes. For example, there is more often marge simpson than kent brockman. We will use a tool later to balance the data and improve the training of our model, this is an important step.   \n",
    "\n",
    "We also need to do a dictionnary to link a `classId` to it's `className` to display some data, it can be usefull but just for us because our model will only use the `classId` to separate the images. Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'bart_simpson', 15: 'nelson_muntz', 8: 'kent_brockman', 14: 'ned_flanders', 16: 'principal_skinner', 0: 'abraham_grampa_simpson', 11: 'marge_simpson', 3: 'charles_montgomery_burns', 5: 'comic_book_guy', 7: 'homer_simpson', 6: 'edna_krabappel', 4: 'chief_wiggum', 10: 'lisa_simpson', 9: 'krusty_the_clown', 13: 'moe_szyslak', 1: 'apu_nahasapeemapetilon', 12: 'milhouse_van_houten', 17: 'sideshow_bob'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionnary to associate a classId to a className.\n",
    "class_dict = dict(zip(df_train['classId'], df_train['className']))\n",
    "\n",
    "# Display data.\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to work with the data to separate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second step : separate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must use our train dataset and split it to use it to train and test our model and check his performances. The test dataset cannot be used for that because it contains the data we want to predict, and we cannot check the effiency of the mdoel with it. We do not need to clean the dataset as saw at the previous step and we will not used the `width` and `heigh` columns of the datasets because they are not usefull. The `className` is usefull just for us, as human, to read the name of the simpson, but the model will use the integer value of the `classId` column to classify the data. We want to separate our data : 80% for train and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset in two sets.\n",
    "data = df_train.sample(frac=1., axis=0, random_state=42)\n",
    "data_train = data.sample(frac=0.8, axis=0, random_state=42) # 80 / 20\n",
    "data_test = data.drop(data_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is separated, we need to process it. In fact, we have here images of different sizes as seen previously, so we need to resize all of them at the same size and also apply a treatment on them. Then it will be possible to use our data to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thrid step: process and normalize data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must resize all the images at the same size. At the first step, we have seen that all the images are larger than 100x100 so we can resize them to a 64x64 format.  \n",
    "We can also preprocess images by applying them an effect, for example, we can apply a gray scale or transform them into RGB images before normalizing them. This step will for sure modify the performance of our model, so we need to do a function if we want to test various solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_and_normalizing(dataframe, folder='train', transformation=0):\n",
    "    out_x_train = []\n",
    "    img_size = (64, 64)\n",
    "    folder = 'datasets/simpsons/' + folder\n",
    "\n",
    "    # Iterate through each image of our dataset.\n",
    "    for i, row in dataframe.iterrows():\n",
    "        # Read image content.\n",
    "        img_path = os.path.join(folder, row['path'])\n",
    "        img_arr = io.imread(img_path)\n",
    "\n",
    "        # Resize image to new shape.\n",
    "        img_arr = transform.resize(img_arr, img_size, preserve_range=True)\n",
    "\n",
    "        # Here come the transformation part. Depending on the tranformation parameter given to the function, something will be apply to the images.\n",
    "        if transformation == 1: # Gray scale.\n",
    "            img_arr = color.rgb2gray(img_arr).reshape(img_size[0], img_size[1], 1)\n",
    "        elif transformation == 2: # Better exposure.\n",
    "            img_arr = exposure.rescale_intensity(img_arr)\n",
    "        elif transformation == 3: # Better exposure + gray scale.\n",
    "            img_arr = exposure.rescale_intensity(img_arr)\n",
    "            img_arr = color.rgb2gray(img_arr).reshape(img_size[0], img_size[1], 1)\n",
    "\n",
    "        # Normalize image and add it to the list.\n",
    "        img_arr = img_arr / 255.\n",
    "\n",
    "        out_x_train.append(img_arr)\n",
    "    \n",
    "    # Return new normalized data.\n",
    "    return out_x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this challenge, I wanted to test other combinations with gray scale or RGB, so I decided to add this transformation parameter in this function and the associated treatments.  \n",
    "\n",
    "Now the data is ready, there is a last thing to do before using it: we mut save it to avoid to reload and process again all the data each time we want to test our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth step: Create a dataset file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use our function to save our data in a h5 file to easily load it again. We first create two functions to load and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants and create folder if not existing.\n",
    "output_folder = 'working/datasets'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def save_dataset(out_x_train, out_x_test, filename):\n",
    "    # Open & create the file and image save data inside to reuse it.\n",
    "    with h5py.File(os.path.join(output_folder, filename), \"w\") as f:\n",
    "        f.create_dataset(\"x_train\", data=out_x_train)\n",
    "        f.create_dataset(\"y_train\", data=data_train.classId.to_numpy())\n",
    "\n",
    "        # Do the same for test data. \n",
    "        f.create_dataset(\"x_test\", data=out_x_test)\n",
    "        f.create_dataset(\"y_test\", data=data_test.classId.to_numpy())\n",
    "\n",
    "def read_dataset(filename):\n",
    "    # Read dataset h5 file.\n",
    "    with h5py.File(os.path.join(output_folder, filename), 'r') as f:\n",
    "        x_train = f['x_train'][:]\n",
    "        y_train = f['y_train'][:]\n",
    "\n",
    "        # Do the same for test data.\n",
    "        x_test = f['x_test'][:]\n",
    "        y_test = f['y_test'][:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let use our functions to load our images from dataframe, process them, save them into different h5 files: one with no processing, one with a gray scale and the other with RGB. This will be usefull later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With no processing. We normalize our two dataframe : train and test and then save them into the file.\n",
    "out_x_train = preprocessing_and_normalizing(data_train)\n",
    "out_x_test = preprocessing_and_normalizing(data_test)\n",
    "save_dataset(out_x_train, out_x_test, \"dataset_standard.h5\")\n",
    "\n",
    "# With gray scale.\n",
    "out_x_train = preprocessing_and_normalizing(data_train, transformation=1)\n",
    "out_x_test = preprocessing_and_normalizing(data_test, transformation=1)\n",
    "save_dataset(out_x_train, out_x_test, \"dataset_gray.h5\")\n",
    "\n",
    "# With RGB (better exposure).\n",
    "out_x_train = preprocessing_and_normalizing(data_train, transformation=2)\n",
    "out_x_test = preprocessing_and_normalizing(data_test, transformation=2)\n",
    "save_dataset(out_x_train, out_x_test, \"dataset_exposure.h5\")\n",
    "\n",
    "# With better exposure + gray scale.\n",
    "out_x_train = preprocessing_and_normalizing(data_train, transformation=3)\n",
    "out_x_test = preprocessing_and_normalizing(data_test, transformation=3)\n",
    "save_dataset(out_x_train, out_x_test, \"dataset_exposure_gray.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let processing the test data now (the thing we want to predict) and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With no processing.\n",
    "out_x_final = preprocessing_and_normalizing(df_test, folder='test')\n",
    "dataset_file_final = os.path.join(output_folder, 'dataset_standard_final.h5')\n",
    "with h5py.File(dataset_file_final, \"w\") as f:\n",
    "    f.create_dataset(\"x_test\",  data=out_x_final)\n",
    "\n",
    "# With gray scale.\n",
    "out_x_final = preprocessing_and_normalizing(df_test, folder='test', transformation=1)\n",
    "dataset_file_final = os.path.join(output_folder, 'dataset_gray_final.h5')\n",
    "with h5py.File(dataset_file_final, \"w\") as f:\n",
    "    f.create_dataset(\"x_test\",  data=out_x_final)\n",
    "\n",
    "# With RGB (better exposure).\n",
    "out_x_final = preprocessing_and_normalizing(df_test, folder='test', transformation=2)\n",
    "dataset_file_final = os.path.join(output_folder, 'dataset_exposure_final.h5')\n",
    "with h5py.File(dataset_file_final, \"w\") as f:\n",
    "    f.create_dataset(\"x_test\",  data=out_x_final)\n",
    "\n",
    "# With better exposure + gray scale.\n",
    "out_x_final = preprocessing_and_normalizing(df_test, folder='test', transformation=3)\n",
    "dataset_file_final = os.path.join(output_folder, 'dataset_exposure_gray_final.h5')\n",
    "with h5py.File(dataset_file_final, \"w\") as f:\n",
    "    f.create_dataset(\"x_test\",  data=out_x_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data we are ready to create a model, train it and see results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth step: read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data saved, let's read it to yuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_standard, y_train_standard, x_test_standard, y_test_standard = read_dataset(\"dataset_standard.h5\")\n",
    "x_train_gray, y_train_gray, x_test_gray, y_test_gray = read_dataset(\"dataset_gray.h5\")\n",
    "x_train_exposure, y_train_exposure, x_test_exposure, y_test_exposure = read_dataset(\"dataset_exposure.h5\")\n",
    "x_train_exposure_gray, y_train_exposure_gray, x_test_exposure_gray, y_test_exposure_gray = read_dataset(\"dataset_exposure_gray.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for our final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(output_folder, 'dataset_standard_final.h5'), 'r') as f:\n",
    "    x_final_standard = f['x_test'][:]\n",
    "with h5py.File(os.path.join(output_folder, 'dataset_gray_final.h5'), 'r') as f:\n",
    "    x_final_gray = f['x_test'][:]\n",
    "with h5py.File(os.path.join(output_folder, 'dataset_exposure_final.h5'), 'r') as f:\n",
    "    x_final_exposure = f['x_test'][:]\n",
    "with h5py.File(os.path.join(output_folder, 'dataset_exposure_gray_final.h5'), 'r') as f:\n",
    "    x_final_exposure_gray = f['x_test'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the sizes to be sure everything is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4366, 64, 64, 3)\n",
      "(4366, 64, 64, 3)\n",
      "(4366, 64, 64, 1)\n",
      "(4366, 64, 64, 1)\n",
      "(1092, 64, 64, 3)\n",
      "(1092, 64, 64, 3)\n",
      "(1092, 64, 64, 1)\n",
      "(1092, 64, 64, 1)\n",
      "(4366,)\n",
      "(4366,)\n",
      "(4366,)\n",
      "(4366,)\n",
      "(1092,)\n",
      "(1092,)\n",
      "(1092,)\n",
      "(1092,)\n",
      "(596, 64, 64, 3)\n",
      "(596, 64, 64, 3)\n",
      "(596, 64, 64, 1)\n",
      "(596, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_exposure.shape)\n",
    "print(x_train_standard.shape)\n",
    "print(x_train_gray.shape)\n",
    "print(x_train_exposure_gray.shape)\n",
    "print(x_test_exposure.shape)\n",
    "print(x_test_standard.shape)\n",
    "print(x_test_gray.shape)\n",
    "print(x_test_exposure_gray.shape)\n",
    "\n",
    "print(y_train_standard.shape)\n",
    "print(y_train_gray.shape)\n",
    "print(y_train_exposure.shape)\n",
    "print(y_train_exposure_gray.shape)\n",
    "print(y_test_exposure.shape)\n",
    "print(y_test_standard.shape)\n",
    "print(y_test_gray.shape)\n",
    "print(y_test_exposure_gray.shape)\n",
    "\n",
    "print(x_final_exposure.shape)\n",
    "print(x_final_standard.shape)\n",
    "print(x_final_gray.shape)\n",
    "print(x_final_exposure_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's seems ok. We note that we have a 3 sized images for the standard and exposure images only, this is beecause they are RGB images, the others are a gray scale. We will try our models on all these types of images to see which one is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sixth step: Create and train a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in the core subject of this project. Our model will be a CNN. We will do NOT use a DNN because we know that the CNN can make better performances than DNN (in overall), so we will directly skip to a CNN. But first, we need to define a `get_model` function to create such a model. But how can we create our model ? This is simple.  \n",
    "\n",
    "* It will be composed of an Input layer which will take the geometry of the input data as a parameter, here 64* 64 * 1 (in our case we will work with images in grayscale, therefore 1 color).\n",
    "* Inputs will be passed to 2 `Conv2D` layers each with a kernel of 3 * 3, a *stride* of 1 and no *padding*. These layers will respectively return a number of 8 and 16 feature maps (*features maps*). The activation functions will be `ReLu`.\n",
    "* A `Flatten` layer which allows the flattening of data into a vector in order to be able to correctly connect our following layers.\n",
    "* Then, two `Dense` layers, both composed of `ReLu` type activation functions and respectively 128 and 32 neurons.\n",
    "* A `Dropout` layer after each hidden layer.\n",
    "* Finally, a final layer of type `Dense` with a number of neurons corresponding to the number of classes to predict (18 different characters). This will be the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cnn_v1(input_shape=(64, 64, 1), dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    Creates a Sequential model for classifying the simpsons using a pooling system.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape (tuple): The shape of input images (default is (64, 64, 1)).\n",
    "    - dropout_rate (float): The droupout rate used in Droupout (default is 0.2).\n",
    "\n",
    "    Returns:\n",
    "    - model (Sequential): The compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layers.\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if len(input_shape) == 3:\n",
    "        model.add(Conv2D(8, kernel_size=(3, 3), strides=1, padding='valid', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(16, kernel_size=(3, 3), strides=1, padding='valid', activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten layer.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layers with Dropout.\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer.\n",
    "    num_classes = 18  # Number of classes (18 simpsons).\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log directory for TensorBoard.\n",
    "log_dir = 'logs/cnn_v1'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the number of parameters to be sure there are not more than 1M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 62, 62, 8)         224       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 31, 31, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 29, 29, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 14, 14, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               401536    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 18)                594       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407650 (1.56 MB)\n",
      "Trainable params: 407650 (1.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_1_standard = get_model_cnn_v1(input_shape=(64, 64, 3)) # Because we use a RGB image we precise the 3 here.\n",
    "model_cnn_1_standard.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good, but the first time I do this, there was over than 7M parameters... To reduce this number I have decided to change my model and add it some pooling to reduce the number of parameters to 400K. Let's train it now. First we will use it on stadard data then try it on the gray scale images, the exposure and the exposure + gray scale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define usefull callbacks.\n",
    "save_callback_1 = keras.callbacks.ModelCheckpoint(filepath=\"models/model_v1\", verbose=0, save_best_only=True)\n",
    "tensorboard_callback_1 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v1_standard\", histogram_freq=1)\n",
    "\n",
    "# Create folders.\n",
    "os.makedirs('models/', exist_ok=True)\n",
    "os.makedirs('logs/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.8743 - accuracy: 0.0735INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 60s 7s/step - loss: 2.8743 - accuracy: 0.0735 - val_loss: 2.8096 - val_accuracy: 0.1795\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.7627 - accuracy: 0.1377INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 684ms/step - loss: 2.7627 - accuracy: 0.1377 - val_loss: 2.6233 - val_accuracy: 0.1941\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.5758 - accuracy: 0.2160INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 567ms/step - loss: 2.5758 - accuracy: 0.2160 - val_loss: 2.3997 - val_accuracy: 0.3425\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.3582 - accuracy: 0.2671INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 659ms/step - loss: 2.3582 - accuracy: 0.2671 - val_loss: 2.0859 - val_accuracy: 0.4396\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.1475 - accuracy: 0.3399INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 760ms/step - loss: 2.1475 - accuracy: 0.3399 - val_loss: 1.8843 - val_accuracy: 0.4661\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.9742 - accuracy: 0.3745INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 590ms/step - loss: 1.9742 - accuracy: 0.3745 - val_loss: 1.6988 - val_accuracy: 0.5293\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.8020 - accuracy: 0.4201INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 590ms/step - loss: 1.8020 - accuracy: 0.4201 - val_loss: 1.5965 - val_accuracy: 0.5540\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.6990 - accuracy: 0.4585INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 685ms/step - loss: 1.6990 - accuracy: 0.4585 - val_loss: 1.4418 - val_accuracy: 0.6053\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.5620 - accuracy: 0.5007INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 707ms/step - loss: 1.5620 - accuracy: 0.5007 - val_loss: 1.3891 - val_accuracy: 0.6227\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.4855 - accuracy: 0.5245INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 602ms/step - loss: 1.4855 - accuracy: 0.5245 - val_loss: 1.2948 - val_accuracy: 0.6557\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.4178 - accuracy: 0.5433INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 635ms/step - loss: 1.4178 - accuracy: 0.5433 - val_loss: 1.2794 - val_accuracy: 0.6538\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.3567 - accuracy: 0.5589INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 728ms/step - loss: 1.3567 - accuracy: 0.5589 - val_loss: 1.2137 - val_accuracy: 0.6612\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.2881 - accuracy: 0.5779INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 670ms/step - loss: 1.2881 - accuracy: 0.5779 - val_loss: 1.1485 - val_accuracy: 0.6941\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.2273 - accuracy: 0.6019INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 8s 934ms/step - loss: 1.2273 - accuracy: 0.6019 - val_loss: 1.0947 - val_accuracy: 0.6996\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.6173INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 719ms/step - loss: 1.1890 - accuracy: 0.6173 - val_loss: 1.0522 - val_accuracy: 0.7152\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 1.1404 - accuracy: 0.6232 - val_loss: 1.0602 - val_accuracy: 0.7143\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.0848 - accuracy: 0.6477INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 669ms/step - loss: 1.0848 - accuracy: 0.6477 - val_loss: 0.9924 - val_accuracy: 0.7234\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.6532INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 744ms/step - loss: 1.0431 - accuracy: 0.6532 - val_loss: 0.9684 - val_accuracy: 0.7381\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 2s 209ms/step - loss: 1.0132 - accuracy: 0.6635 - val_loss: 0.9712 - val_accuracy: 0.7216\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9729 - accuracy: 0.6725INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 8s 972ms/step - loss: 0.9729 - accuracy: 0.6725 - val_loss: 0.9340 - val_accuracy: 0.7454\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.9348 - accuracy: 0.6940 - val_loss: 0.9451 - val_accuracy: 0.7427\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.6984INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 568ms/step - loss: 0.9150 - accuracy: 0.6984 - val_loss: 0.9111 - val_accuracy: 0.7518\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8991 - accuracy: 0.6990INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 538ms/step - loss: 0.8991 - accuracy: 0.6990 - val_loss: 0.8951 - val_accuracy: 0.7491\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 2s 256ms/step - loss: 0.8642 - accuracy: 0.7146 - val_loss: 0.8956 - val_accuracy: 0.7518\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.8356 - accuracy: 0.7158INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 603ms/step - loss: 0.8356 - accuracy: 0.7158 - val_loss: 0.8762 - val_accuracy: 0.7564\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 2s 236ms/step - loss: 0.8142 - accuracy: 0.7231 - val_loss: 0.8808 - val_accuracy: 0.7619\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7817 - accuracy: 0.7316INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 782ms/step - loss: 0.7817 - accuracy: 0.7316 - val_loss: 0.8711 - val_accuracy: 0.7564\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7586 - accuracy: 0.7412INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 625ms/step - loss: 0.7586 - accuracy: 0.7412 - val_loss: 0.8535 - val_accuracy: 0.7683\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7612 - accuracy: 0.7300INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 7s 863ms/step - loss: 0.7612 - accuracy: 0.7300 - val_loss: 0.8497 - val_accuracy: 0.7674\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 5s 571ms/step - loss: 0.7208 - accuracy: 0.7542 - val_loss: 0.8510 - val_accuracy: 0.7637\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6843 - accuracy: 0.7611INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 707ms/step - loss: 0.6843 - accuracy: 0.7611 - val_loss: 0.8419 - val_accuracy: 0.7656\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 2s 281ms/step - loss: 0.6880 - accuracy: 0.7545 - val_loss: 0.8483 - val_accuracy: 0.7601\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.7618INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 686ms/step - loss: 0.6712 - accuracy: 0.7618 - val_loss: 0.8337 - val_accuracy: 0.7701\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.7645INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 666ms/step - loss: 0.6640 - accuracy: 0.7645 - val_loss: 0.8332 - val_accuracy: 0.7711\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6414 - accuracy: 0.7664INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 646ms/step - loss: 0.6414 - accuracy: 0.7664 - val_loss: 0.8250 - val_accuracy: 0.7683\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.6256 - accuracy: 0.7787INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 603ms/step - loss: 0.6256 - accuracy: 0.7787 - val_loss: 0.8149 - val_accuracy: 0.7701\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.7911INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 616ms/step - loss: 0.5880 - accuracy: 0.7911 - val_loss: 0.8072 - val_accuracy: 0.7756\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 3s 360ms/step - loss: 0.5800 - accuracy: 0.7870 - val_loss: 0.8251 - val_accuracy: 0.7701\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7785INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 9s 1s/step - loss: 0.5929 - accuracy: 0.7785 - val_loss: 0.8002 - val_accuracy: 0.7875\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.5571 - accuracy: 0.7943 - val_loss: 0.8219 - val_accuracy: 0.7729\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5318 - accuracy: 0.8046 - val_loss: 0.8100 - val_accuracy: 0.7830\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.5315 - accuracy: 0.8085 - val_loss: 0.8200 - val_accuracy: 0.7830\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 2s 273ms/step - loss: 0.5365 - accuracy: 0.7991 - val_loss: 0.8112 - val_accuracy: 0.7775\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8099INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 7s 801ms/step - loss: 0.5059 - accuracy: 0.8099 - val_loss: 0.7968 - val_accuracy: 0.7830\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5053 - accuracy: 0.8113 - val_loss: 0.8117 - val_accuracy: 0.7729\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.5014 - accuracy: 0.8069 - val_loss: 0.8129 - val_accuracy: 0.7793\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 3s 386ms/step - loss: 0.4870 - accuracy: 0.8165 - val_loss: 0.8132 - val_accuracy: 0.7756\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 0.4693 - accuracy: 0.8195 - val_loss: 0.8030 - val_accuracy: 0.7793\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 0.4470 - accuracy: 0.8307 - val_loss: 0.8027 - val_accuracy: 0.7830\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4296 - accuracy: 0.8339INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 495ms/step - loss: 0.4296 - accuracy: 0.8339 - val_loss: 0.7879 - val_accuracy: 0.7766\n"
     ]
    }
   ],
   "source": [
    "samples_weight = compute_sample_weight(\"balanced\", y_train_standard) # Used to manage inbalanced data.\n",
    "\n",
    "model_cnn_1_standard.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on 50 epochs.\n",
    "history_v1_standard = model_cnn_1_standard.fit(\n",
    "    x=x_train_standard,\n",
    "    y=y_train_standard,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_1, tensorboard_callback_1],\n",
    "    validation_data=(x_test_standard, y_test_standard),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now renew the operation with each of the previous image types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 427ms/step - loss: 2.8870 - accuracy: 0.0747 - val_loss: 2.8760 - val_accuracy: 0.1538\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 2.8547 - accuracy: 0.1280 - val_loss: 2.7892 - val_accuracy: 0.2125\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 3s 371ms/step - loss: 2.7870 - accuracy: 0.1697 - val_loss: 2.6686 - val_accuracy: 0.2674\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 2.6706 - accuracy: 0.1958 - val_loss: 2.5030 - val_accuracy: 0.2711\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 2.5351 - accuracy: 0.2089 - val_loss: 2.3527 - val_accuracy: 0.2857\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 2.4323 - accuracy: 0.2414 - val_loss: 2.2201 - val_accuracy: 0.3114\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 2.3481 - accuracy: 0.2533 - val_loss: 2.1441 - val_accuracy: 0.3516\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 3s 276ms/step - loss: 2.2717 - accuracy: 0.2792 - val_loss: 2.0964 - val_accuracy: 0.3544\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 2.2057 - accuracy: 0.2897 - val_loss: 2.0370 - val_accuracy: 0.3965\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 2.1537 - accuracy: 0.3138 - val_loss: 1.9808 - val_accuracy: 0.4304\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 2.1087 - accuracy: 0.3433 - val_loss: 1.9412 - val_accuracy: 0.4304\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 2.0646 - accuracy: 0.3397 - val_loss: 1.9008 - val_accuracy: 0.4414\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 2s 257ms/step - loss: 2.0317 - accuracy: 0.3433 - val_loss: 1.8714 - val_accuracy: 0.4661\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 1.9572 - accuracy: 0.3717 - val_loss: 1.8386 - val_accuracy: 0.4716\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 1.9381 - accuracy: 0.3678 - val_loss: 1.8301 - val_accuracy: 0.4679\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 2s 271ms/step - loss: 1.9111 - accuracy: 0.3830 - val_loss: 1.7813 - val_accuracy: 0.4963\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 2s 218ms/step - loss: 1.8565 - accuracy: 0.4116 - val_loss: 1.7521 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 1.8167 - accuracy: 0.4130 - val_loss: 1.7240 - val_accuracy: 0.5156\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 2s 260ms/step - loss: 1.7770 - accuracy: 0.4187 - val_loss: 1.6856 - val_accuracy: 0.5147\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 1.7416 - accuracy: 0.4450 - val_loss: 1.6804 - val_accuracy: 0.5046\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 1.7167 - accuracy: 0.4519 - val_loss: 1.6550 - val_accuracy: 0.5147\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 1.6898 - accuracy: 0.4501 - val_loss: 1.6282 - val_accuracy: 0.5385\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 1.6377 - accuracy: 0.4661 - val_loss: 1.6283 - val_accuracy: 0.5449\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 1.6179 - accuracy: 0.4702 - val_loss: 1.5732 - val_accuracy: 0.5586\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 1.5554 - accuracy: 0.4986 - val_loss: 1.5609 - val_accuracy: 0.5357\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.5339 - accuracy: 0.5032 - val_loss: 1.5528 - val_accuracy: 0.5577\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 1.4668 - accuracy: 0.5135 - val_loss: 1.5425 - val_accuracy: 0.5430\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 1.4723 - accuracy: 0.5027 - val_loss: 1.5438 - val_accuracy: 0.5394\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 2s 258ms/step - loss: 1.4151 - accuracy: 0.5204 - val_loss: 1.4789 - val_accuracy: 0.5614\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 1.3700 - accuracy: 0.5339 - val_loss: 1.4568 - val_accuracy: 0.5760\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 1.3439 - accuracy: 0.5442 - val_loss: 1.4446 - val_accuracy: 0.5687\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 2s 257ms/step - loss: 1.3334 - accuracy: 0.5424 - val_loss: 1.4206 - val_accuracy: 0.5824\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.3065 - accuracy: 0.5563 - val_loss: 1.4360 - val_accuracy: 0.5778\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 1.2900 - accuracy: 0.5598 - val_loss: 1.4368 - val_accuracy: 0.5824\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 1.2510 - accuracy: 0.5696 - val_loss: 1.4125 - val_accuracy: 0.5824\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 1.2067 - accuracy: 0.5845 - val_loss: 1.3809 - val_accuracy: 0.5971\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 1.1985 - accuracy: 0.5825 - val_loss: 1.3559 - val_accuracy: 0.6053\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 1.1740 - accuracy: 0.5941 - val_loss: 1.3596 - val_accuracy: 0.6108\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 1.1380 - accuracy: 0.5985 - val_loss: 1.3520 - val_accuracy: 0.6007\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 1.0958 - accuracy: 0.6173 - val_loss: 1.3191 - val_accuracy: 0.6190\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 1.1247 - accuracy: 0.6033 - val_loss: 1.3648 - val_accuracy: 0.5980\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 2s 220ms/step - loss: 1.1043 - accuracy: 0.6005 - val_loss: 1.3427 - val_accuracy: 0.6154\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 1.0462 - accuracy: 0.6264 - val_loss: 1.3120 - val_accuracy: 0.6136\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 1.0320 - accuracy: 0.6349 - val_loss: 1.3124 - val_accuracy: 0.6218\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.0054 - accuracy: 0.6351 - val_loss: 1.3008 - val_accuracy: 0.6181\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 0.9785 - accuracy: 0.6493 - val_loss: 1.2891 - val_accuracy: 0.6282\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.9339 - accuracy: 0.6555 - val_loss: 1.2814 - val_accuracy: 0.6227\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 0.9175 - accuracy: 0.6677 - val_loss: 1.2720 - val_accuracy: 0.6300\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 254ms/step - loss: 0.9101 - accuracy: 0.6622 - val_loss: 1.2647 - val_accuracy: 0.6273\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 0.8861 - accuracy: 0.6688 - val_loss: 1.2763 - val_accuracy: 0.6291\n"
     ]
    }
   ],
   "source": [
    "# Gray scale.\n",
    "model_cnn_1_gray = get_model_cnn_v1(input_shape=(64, 64, 1))\n",
    "tensorboard_callback_1 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v1_gray\", histogram_freq=1)\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_gray)\n",
    "model_cnn_1_gray.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v1_gray = model_cnn_1_gray.fit(\n",
    "    x=x_train_gray,\n",
    "    y=y_train_gray,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_1, tensorboard_callback_1],\n",
    "    validation_data=(x_test_gray, y_test_gray),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 21s 1s/step - loss: 2.8904 - accuracy: 0.0822 - val_loss: 2.8881 - val_accuracy: 0.0852\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 4s 434ms/step - loss: 2.8889 - accuracy: 0.0902 - val_loss: 2.8838 - val_accuracy: 0.0943\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 4s 403ms/step - loss: 2.8834 - accuracy: 0.0978 - val_loss: 2.8655 - val_accuracy: 0.0916\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 4s 488ms/step - loss: 2.8730 - accuracy: 0.1054 - val_loss: 2.8363 - val_accuracy: 0.1136\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 4s 411ms/step - loss: 2.8479 - accuracy: 0.1326 - val_loss: 2.7986 - val_accuracy: 0.1200\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 2.8020 - accuracy: 0.1422 - val_loss: 2.7299 - val_accuracy: 0.1273\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 4s 416ms/step - loss: 2.7260 - accuracy: 0.1427 - val_loss: 2.6005 - val_accuracy: 0.1474\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 4s 393ms/step - loss: 2.6351 - accuracy: 0.1619 - val_loss: 2.5001 - val_accuracy: 0.1804\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 4s 437ms/step - loss: 2.5601 - accuracy: 0.1874 - val_loss: 2.3776 - val_accuracy: 0.2592\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 2.4790 - accuracy: 0.2151 - val_loss: 2.2614 - val_accuracy: 0.3022\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 4s 399ms/step - loss: 2.4199 - accuracy: 0.2366 - val_loss: 2.1919 - val_accuracy: 0.3278\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 4s 436ms/step - loss: 2.3548 - accuracy: 0.2641 - val_loss: 2.1269 - val_accuracy: 0.3434\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 4s 435ms/step - loss: 2.3384 - accuracy: 0.2517 - val_loss: 2.0681 - val_accuracy: 0.3443\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 4s 456ms/step - loss: 2.2931 - accuracy: 0.2732 - val_loss: 2.0852 - val_accuracy: 0.3526\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 4s 489ms/step - loss: 2.2685 - accuracy: 0.2753 - val_loss: 2.0041 - val_accuracy: 0.3690\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 4s 380ms/step - loss: 2.2382 - accuracy: 0.2884 - val_loss: 1.9873 - val_accuracy: 0.3837\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 4s 431ms/step - loss: 2.2241 - accuracy: 0.2904 - val_loss: 1.9796 - val_accuracy: 0.3846\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 3s 385ms/step - loss: 2.1791 - accuracy: 0.3010 - val_loss: 1.9262 - val_accuracy: 0.3984\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 4s 433ms/step - loss: 2.1592 - accuracy: 0.3087 - val_loss: 1.9141 - val_accuracy: 0.4011\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 4s 389ms/step - loss: 2.1527 - accuracy: 0.3142 - val_loss: 1.8981 - val_accuracy: 0.3956\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 3s 391ms/step - loss: 2.1340 - accuracy: 0.3181 - val_loss: 1.8859 - val_accuracy: 0.4029\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 4s 448ms/step - loss: 2.1168 - accuracy: 0.3191 - val_loss: 1.8849 - val_accuracy: 0.4139\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 4s 425ms/step - loss: 2.1009 - accuracy: 0.3241 - val_loss: 1.8459 - val_accuracy: 0.4167\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 4s 398ms/step - loss: 2.0917 - accuracy: 0.3294 - val_loss: 1.9053 - val_accuracy: 0.4029\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 5s 581ms/step - loss: 2.0787 - accuracy: 0.3262 - val_loss: 1.8433 - val_accuracy: 0.4295\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 4s 501ms/step - loss: 2.0526 - accuracy: 0.3507 - val_loss: 1.8156 - val_accuracy: 0.4313\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 5s 624ms/step - loss: 2.0550 - accuracy: 0.3436 - val_loss: 1.8335 - val_accuracy: 0.4286\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 4s 468ms/step - loss: 2.0235 - accuracy: 0.3481 - val_loss: 1.8011 - val_accuracy: 0.4524\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 4s 436ms/step - loss: 1.9994 - accuracy: 0.3580 - val_loss: 1.7826 - val_accuracy: 0.4441\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 4s 408ms/step - loss: 2.0040 - accuracy: 0.3520 - val_loss: 1.7874 - val_accuracy: 0.4386\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 1.9967 - accuracy: 0.3685 - val_loss: 1.7809 - val_accuracy: 0.4597\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 3s 398ms/step - loss: 1.9649 - accuracy: 0.3713 - val_loss: 1.7724 - val_accuracy: 0.4679\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 1.9626 - accuracy: 0.3683 - val_loss: 1.7536 - val_accuracy: 0.4606\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 5s 627ms/step - loss: 1.9402 - accuracy: 0.3864 - val_loss: 1.7453 - val_accuracy: 0.4634\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 4s 467ms/step - loss: 1.9366 - accuracy: 0.3830 - val_loss: 1.7533 - val_accuracy: 0.4734\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 5s 537ms/step - loss: 1.9483 - accuracy: 0.3816 - val_loss: 1.7311 - val_accuracy: 0.4753\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 4s 333ms/step - loss: 1.9133 - accuracy: 0.3859 - val_loss: 1.7178 - val_accuracy: 0.4780\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 4s 427ms/step - loss: 1.9077 - accuracy: 0.3765 - val_loss: 1.7594 - val_accuracy: 0.4799\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 4s 406ms/step - loss: 1.9120 - accuracy: 0.3830 - val_loss: 1.7039 - val_accuracy: 0.4780\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 4s 435ms/step - loss: 1.9213 - accuracy: 0.3839 - val_loss: 1.7103 - val_accuracy: 0.4890\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 4s 418ms/step - loss: 1.9254 - accuracy: 0.3820 - val_loss: 1.7197 - val_accuracy: 0.4881\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 4s 457ms/step - loss: 1.8894 - accuracy: 0.3859 - val_loss: 1.6795 - val_accuracy: 0.4918\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 3s 366ms/step - loss: 1.8835 - accuracy: 0.3969 - val_loss: 1.6855 - val_accuracy: 0.4918\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 4s 409ms/step - loss: 1.8536 - accuracy: 0.4082 - val_loss: 1.6749 - val_accuracy: 0.4918\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 3s 345ms/step - loss: 1.8357 - accuracy: 0.4063 - val_loss: 1.6755 - val_accuracy: 0.4890\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 3s 378ms/step - loss: 1.8675 - accuracy: 0.4052 - val_loss: 1.6548 - val_accuracy: 0.5101\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 3s 372ms/step - loss: 1.8337 - accuracy: 0.4141 - val_loss: 1.6625 - val_accuracy: 0.4890\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 3s 290ms/step - loss: 1.8437 - accuracy: 0.4061 - val_loss: 1.6614 - val_accuracy: 0.5046\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 271ms/step - loss: 1.8317 - accuracy: 0.4214 - val_loss: 1.6591 - val_accuracy: 0.5082\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 3s 350ms/step - loss: 1.8059 - accuracy: 0.4217 - val_loss: 1.6393 - val_accuracy: 0.4954\n"
     ]
    }
   ],
   "source": [
    "# Exposure.\n",
    "model_cnn_1_exposure = get_model_cnn_v1(input_shape=(64, 64, 3))\n",
    "tensorboard_callback_1 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v1_exposure\", histogram_freq=1)\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_exposure)\n",
    "model_cnn_1_exposure.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v1_exposure = model_cnn_1_exposure.fit(\n",
    "    x=x_train_exposure,\n",
    "    y=y_train_exposure,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_1, tensorboard_callback_1],\n",
    "    validation_data=(x_test_exposure, y_test_exposure),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 13s 779ms/step - loss: 2.8907 - accuracy: 0.0341 - val_loss: 2.8911 - val_accuracy: 0.0275\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 4s 433ms/step - loss: 2.8905 - accuracy: 0.0314 - val_loss: 2.8904 - val_accuracy: 0.0275\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 3s 357ms/step - loss: 2.8904 - accuracy: 0.0520 - val_loss: 2.8904 - val_accuracy: 0.0897\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 3s 370ms/step - loss: 2.8905 - accuracy: 0.0579 - val_loss: 2.8903 - val_accuracy: 0.0897\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 2.8904 - accuracy: 0.0630 - val_loss: 2.8902 - val_accuracy: 0.0897\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 4s 416ms/step - loss: 2.8904 - accuracy: 0.0683 - val_loss: 2.8901 - val_accuracy: 0.0897\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 2s 279ms/step - loss: 2.8904 - accuracy: 0.0683 - val_loss: 2.8901 - val_accuracy: 0.0897\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 2s 285ms/step - loss: 2.8904 - accuracy: 0.0680 - val_loss: 2.8901 - val_accuracy: 0.0897\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 2.8904 - accuracy: 0.0646 - val_loss: 2.8899 - val_accuracy: 0.0275\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 2.8904 - accuracy: 0.0399 - val_loss: 2.8900 - val_accuracy: 0.0275\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 2s 269ms/step - loss: 2.8904 - accuracy: 0.0488 - val_loss: 2.8901 - val_accuracy: 0.0275\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 2.8905 - accuracy: 0.0403 - val_loss: 2.8902 - val_accuracy: 0.0266\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 2s 283ms/step - loss: 2.8904 - accuracy: 0.0424 - val_loss: 2.8901 - val_accuracy: 0.0275\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 3s 286ms/step - loss: 2.8904 - accuracy: 0.0486 - val_loss: 2.8902 - val_accuracy: 0.0266\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 3s 293ms/step - loss: 2.8905 - accuracy: 0.0557 - val_loss: 2.8901 - val_accuracy: 0.0971\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 2s 288ms/step - loss: 2.8904 - accuracy: 0.0841 - val_loss: 2.8902 - val_accuracy: 0.0971\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 2.8904 - accuracy: 0.0708 - val_loss: 2.8900 - val_accuracy: 0.0650\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 2s 212ms/step - loss: 2.8904 - accuracy: 0.0756 - val_loss: 2.8900 - val_accuracy: 0.0971\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 2.8904 - accuracy: 0.0774 - val_loss: 2.8900 - val_accuracy: 0.0201\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 2.8904 - accuracy: 0.0623 - val_loss: 2.8902 - val_accuracy: 0.0897\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 2s 256ms/step - loss: 2.8904 - accuracy: 0.0618 - val_loss: 2.8900 - val_accuracy: 0.0897\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 2s 271ms/step - loss: 2.8905 - accuracy: 0.0701 - val_loss: 2.8899 - val_accuracy: 0.0897\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 2.8903 - accuracy: 0.0667 - val_loss: 2.8900 - val_accuracy: 0.0897\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 2s 267ms/step - loss: 2.8905 - accuracy: 0.0669 - val_loss: 2.8898 - val_accuracy: 0.0897\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 2.8904 - accuracy: 0.0650 - val_loss: 2.8899 - val_accuracy: 0.0897\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 2.8905 - accuracy: 0.0618 - val_loss: 2.8900 - val_accuracy: 0.0897\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 2s 262ms/step - loss: 2.8905 - accuracy: 0.0689 - val_loss: 2.8900 - val_accuracy: 0.0897\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 2.8904 - accuracy: 0.0671 - val_loss: 2.8901 - val_accuracy: 0.0201\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 3s 374ms/step - loss: 2.8904 - accuracy: 0.0717 - val_loss: 2.8903 - val_accuracy: 0.0897\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 2.8904 - accuracy: 0.0577 - val_loss: 2.8903 - val_accuracy: 0.0897\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 2.8905 - accuracy: 0.0566 - val_loss: 2.8901 - val_accuracy: 0.0897\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 2.8904 - accuracy: 0.0630 - val_loss: 2.8901 - val_accuracy: 0.0897\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 2.8904 - accuracy: 0.0598 - val_loss: 2.8901 - val_accuracy: 0.0897\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 3s 388ms/step - loss: 2.8905 - accuracy: 0.0582 - val_loss: 2.8902 - val_accuracy: 0.0897\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 2.8904 - accuracy: 0.0573 - val_loss: 2.8903 - val_accuracy: 0.0403\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 2.8904 - accuracy: 0.0490 - val_loss: 2.8904 - val_accuracy: 0.0403\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 2s 262ms/step - loss: 2.8904 - accuracy: 0.0323 - val_loss: 2.8903 - val_accuracy: 0.0403\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 2.8904 - accuracy: 0.0348 - val_loss: 2.8904 - val_accuracy: 0.0403\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 2s 218ms/step - loss: 2.8904 - accuracy: 0.0479 - val_loss: 2.8903 - val_accuracy: 0.0852\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 2s 216ms/step - loss: 2.8905 - accuracy: 0.0357 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 2.8904 - accuracy: 0.0250 - val_loss: 2.8906 - val_accuracy: 0.0375\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 2.8904 - accuracy: 0.0286 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 3s 376ms/step - loss: 2.8904 - accuracy: 0.0289 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 3s 295ms/step - loss: 2.8904 - accuracy: 0.0273 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 2.8904 - accuracy: 0.0295 - val_loss: 2.8905 - val_accuracy: 0.0403\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 2.8904 - accuracy: 0.0295 - val_loss: 2.8905 - val_accuracy: 0.0403\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 2.8904 - accuracy: 0.0318 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 2.8904 - accuracy: 0.0275 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 242ms/step - loss: 2.8903 - accuracy: 0.0270 - val_loss: 2.8905 - val_accuracy: 0.0375\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 2.8904 - accuracy: 0.0559 - val_loss: 2.8904 - val_accuracy: 0.0852\n"
     ]
    }
   ],
   "source": [
    "# Exposure + gray scale.\n",
    "model_cnn_1_exposure_gray = get_model_cnn_v1(input_shape=(64, 64, 1))\n",
    "tensorboard_callback_1 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v1_exposure_gray\", histogram_freq=1)\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_exposure_gray)\n",
    "model_cnn_1_exposure_gray.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v1_exposure_gray = model_cnn_1_exposure_gray.fit(\n",
    "    x=x_train_exposure_gray,\n",
    "    y=y_train_exposure_gray,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_1, tensorboard_callback_1],\n",
    "    validation_data=(x_test_exposure_gray, y_test_exposure_gray),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let print a simple graph to compare the performance between the accuracy between the 4 types of images. We can also see the accuracy in tensorboard but juste readibility purpose I will print this graphic here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot accuracy for the models with convolutional layers.\n",
    "plt.plot(history_v1_standard.history['accuracy'], label='Train Standard')\n",
    "plt.plot(history_v1_standard.history['val_accuracy'], label='Validation Standard')\n",
    "\n",
    "plt.plot(history_v1_gray.history['accuracy'], label='Train Gray')\n",
    "plt.plot(history_v1_gray.history['val_accuracy'], label='Validation Gray')\n",
    "\n",
    "plt.plot(history_v1_exposure.history['accuracy'], label='Train Exposure')\n",
    "plt.plot(history_v1_exposure.history['val_accuracy'], label='Validation Exposure')\n",
    "\n",
    "plt.plot(history_v1_exposure_gray.history['accuracy'], label='Train Gray + Exposure')\n",
    "plt.plot(history_v1_exposure_gray.history['val_accuracy'], label='Validation Gray + Exposure')\n",
    "\n",
    "plt.title('Training and Validation Accuracy Comparison Between Models')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the best performances for the standard images, it seems that using other transformations just reduce the accuracy... The simple's the best like we say. The standard model achieve the best performance but the gray scale model is not too bad as well. I suppose all the models are good but it seems the gray one and the standard one are the best. The exposure + gray scale model is just catastrophic. I We will continue to use all of these 3 models even if I don't think the exposure is relevant... It seems logical to say that the more the pictures are detailed, the easiest the model find the good answer.  \n",
    "I am going to submit the performance of the standard and gray scale model. For that, I must train it on all the train data, so I will group my two lists and then save the content into a CSV file to submit my work on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5458, 64, 64, 3)\n",
      "(5458,)\n",
      "(5458, 64, 64, 1)\n",
      "(5458,)\n"
     ]
    }
   ],
   "source": [
    "# Add all train dataset.\n",
    "x_train_total_standard = np.concatenate((x_train_standard, x_test_standard), axis=0)\n",
    "y_train_total_standard = np.concatenate((y_train_standard, y_test_standard), axis=0)\n",
    "\n",
    "x_train_total_gray = np.concatenate((x_train_gray, x_test_gray), axis=0)\n",
    "y_train_total_gray = np.concatenate((y_train_gray, y_test_gray), axis=0)\n",
    "\n",
    "print(x_train_total_standard.shape)\n",
    "print(y_train_total_standard.shape)\n",
    "\n",
    "print(x_train_total_gray.shape)\n",
    "print(y_train_total_gray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train again our models with all data and make them predict results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.8189 - accuracy: 0.1444WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 31s 1s/step - loss: 2.8189 - accuracy: 0.1444\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.5416 - accuracy: 0.2266WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 378ms/step - loss: 2.5416 - accuracy: 0.2266\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 2.2521 - accuracy: 0.3179WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 386ms/step - loss: 2.2521 - accuracy: 0.3179\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.9829 - accuracy: 0.3930WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 309ms/step - loss: 1.9829 - accuracy: 0.3930\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.7668 - accuracy: 0.4580WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 441ms/step - loss: 1.7668 - accuracy: 0.4580\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.5904 - accuracy: 0.4943WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 499ms/step - loss: 1.5904 - accuracy: 0.4943\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4742 - accuracy: 0.5436WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 562ms/step - loss: 1.4742 - accuracy: 0.5436\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.4017 - accuracy: 0.5540WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 451ms/step - loss: 1.4017 - accuracy: 0.5540\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.3326 - accuracy: 0.5795WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 629ms/step - loss: 1.3326 - accuracy: 0.5795\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.2124 - accuracy: 0.6141WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 633ms/step - loss: 1.2124 - accuracy: 0.6141\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1211 - accuracy: 0.6414WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 468ms/step - loss: 1.1211 - accuracy: 0.6414\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.6557WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 431ms/step - loss: 1.0863 - accuracy: 0.6557\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0243 - accuracy: 0.6654WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 403ms/step - loss: 1.0243 - accuracy: 0.6654\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.6841WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 533ms/step - loss: 0.9758 - accuracy: 0.6841\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9274 - accuracy: 0.6964WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 563ms/step - loss: 0.9274 - accuracy: 0.6964\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8753 - accuracy: 0.7142WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 424ms/step - loss: 0.8753 - accuracy: 0.7142\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8510 - accuracy: 0.7211WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 367ms/step - loss: 0.8510 - accuracy: 0.7211\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8308 - accuracy: 0.7182WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 338ms/step - loss: 0.8308 - accuracy: 0.7182\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7627 - accuracy: 0.7486WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 368ms/step - loss: 0.7627 - accuracy: 0.7486\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7114 - accuracy: 0.7662WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 442ms/step - loss: 0.7114 - accuracy: 0.7662\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7023 - accuracy: 0.7626WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 483ms/step - loss: 0.7023 - accuracy: 0.7626\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.7671WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 400ms/step - loss: 0.6731 - accuracy: 0.7671\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6342 - accuracy: 0.7803WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 456ms/step - loss: 0.6342 - accuracy: 0.7803\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6144 - accuracy: 0.7856WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 430ms/step - loss: 0.6144 - accuracy: 0.7856\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.7873WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 441ms/step - loss: 0.6084 - accuracy: 0.7873\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.8032WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 503ms/step - loss: 0.5622 - accuracy: 0.8032\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5463 - accuracy: 0.8091WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 366ms/step - loss: 0.5463 - accuracy: 0.8091\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.8137WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 412ms/step - loss: 0.5207 - accuracy: 0.8137\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8250WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 391ms/step - loss: 0.4947 - accuracy: 0.8250\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.8292WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 510ms/step - loss: 0.4747 - accuracy: 0.8292\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.8302WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 514ms/step - loss: 0.4571 - accuracy: 0.8302\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.8388WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 555ms/step - loss: 0.4389 - accuracy: 0.8388\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.8408WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 334ms/step - loss: 0.4165 - accuracy: 0.8408\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8465WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 342ms/step - loss: 0.4036 - accuracy: 0.8465\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8551WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 361ms/step - loss: 0.3927 - accuracy: 0.8551\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8620WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 415ms/step - loss: 0.3732 - accuracy: 0.8620\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.8602WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 447ms/step - loss: 0.3611 - accuracy: 0.8602\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8758WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 512ms/step - loss: 0.3372 - accuracy: 0.8758\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.8745WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 8s 758ms/step - loss: 0.3378 - accuracy: 0.8745\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.8802WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 451ms/step - loss: 0.3129 - accuracy: 0.8802\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.8838WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 371ms/step - loss: 0.3000 - accuracy: 0.8838\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.8835WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 379ms/step - loss: 0.2990 - accuracy: 0.8835\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.8930WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 336ms/step - loss: 0.2759 - accuracy: 0.8930\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.8936WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 337ms/step - loss: 0.2715 - accuracy: 0.8936\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.8981WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 319ms/step - loss: 0.2558 - accuracy: 0.8981\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.9049WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 356ms/step - loss: 0.2502 - accuracy: 0.9049\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.9042WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 285ms/step - loss: 0.2458 - accuracy: 0.9042\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9071WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 228ms/step - loss: 0.2437 - accuracy: 0.9071\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.9040WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 291ms/step - loss: 0.2340 - accuracy: 0.9040\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9122WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 214ms/step - loss: 0.2261 - accuracy: 0.9122\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 7s 164ms/step - loss: 2.8823 - accuracy: 0.0802\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 2s 167ms/step - loss: 2.8315 - accuracy: 0.0845\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 2s 213ms/step - loss: 2.7349 - accuracy: 0.1407\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 2.5941 - accuracy: 0.1854\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 2.4481 - accuracy: 0.2160\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 2s 201ms/step - loss: 2.3265 - accuracy: 0.2640\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 2s 180ms/step - loss: 2.2381 - accuracy: 0.3027\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 2.1496 - accuracy: 0.3267\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 2.0864 - accuracy: 0.3459\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 2.0389 - accuracy: 0.3730\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 1.9764 - accuracy: 0.3840\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 1.9181 - accuracy: 0.4086\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 1.8727 - accuracy: 0.4077\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 1.8090 - accuracy: 0.4318\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 1.7494 - accuracy: 0.4505\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 2s 171ms/step - loss: 1.7012 - accuracy: 0.4764\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 1.6489 - accuracy: 0.4789\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 1.5839 - accuracy: 0.5073\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 1.5648 - accuracy: 0.5044\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 1.5199 - accuracy: 0.5148\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 1.4671 - accuracy: 0.5302\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 1.4192 - accuracy: 0.5438\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 1.3910 - accuracy: 0.5526\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 1.3522 - accuracy: 0.5630\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 1.3224 - accuracy: 0.5726\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 1.2954 - accuracy: 0.5885\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 1.2450 - accuracy: 0.5890\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 1.1883 - accuracy: 0.6074\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 1.1620 - accuracy: 0.6154\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 1.1373 - accuracy: 0.6228\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 1.1170 - accuracy: 0.6261\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 1.0910 - accuracy: 0.6359\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 2s 168ms/step - loss: 1.0658 - accuracy: 0.6326\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 1.0414 - accuracy: 0.6354\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.9904 - accuracy: 0.6545\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.9757 - accuracy: 0.6647\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.9558 - accuracy: 0.6697\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 3s 216ms/step - loss: 0.9330 - accuracy: 0.6715\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.8795 - accuracy: 0.6852\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.8809 - accuracy: 0.6882\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.8640 - accuracy: 0.6893\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 2s 139ms/step - loss: 0.8420 - accuracy: 0.7036\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 2s 137ms/step - loss: 0.7957 - accuracy: 0.7081\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.7760 - accuracy: 0.7120\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 0.7664 - accuracy: 0.7217\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 0.7592 - accuracy: 0.7309\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.7437 - accuracy: 0.7307\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.7300 - accuracy: 0.7395\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.7252 - accuracy: 0.7393\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 0.6962 - accuracy: 0.7451\n"
     ]
    }
   ],
   "source": [
    "# Standard.\n",
    "model_cnn_1_standard_total = get_model_cnn_v1(input_shape=(64, 64, 3))\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_total_standard)\n",
    "model_cnn_1_standard_total.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v1_standard = model_cnn_1_standard_total.fit(\n",
    "    x=x_train_total_standard,\n",
    "    y=y_train_total_standard,\n",
    "    batch_size=512,\n",
    "    epochs=50,\n",
    "    sample_weight=samples_weight\n",
    ")\n",
    "\n",
    "# Gray scale.\n",
    "model_cnn_1_gray_total = get_model_cnn_v1(input_shape=(64, 64, 1))\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_total_gray)\n",
    "model_cnn_1_gray_total.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v1_gray = model_cnn_1_gray_total.fit(\n",
    "    x=x_train_total_gray,\n",
    "    y=y_train_total_gray,\n",
    "    batch_size=512,\n",
    "    epochs=50,\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save ou results now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('working/predictions', exist_ok=True)\n",
    "y_prediction_standard = model_cnn_1_standard_total.predict(x_final_standard)\n",
    "y_prediction_standard = np.argmax(y_prediction_standard, axis=1)\n",
    "result = pd.DataFrame({'path': df_test.path, 'classId': y_prediction_standard})\n",
    "result.to_csv('working/predictions/submission_model_1_standard.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results : an accuracy of 0.80, not too bad I suppose but it can stille be improved. To do that, we are going to do the same process but with another model. We will dropout layers to try to increase the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cnn_v2(input_shape=(64, 64, 1)):\n",
    "    \"\"\"\n",
    "    Creates a Sequential model for classifying the simpsons using pooling and dropout layers.\n",
    "\n",
    "    Parameters:\n",
    "    - input_shape (tuple): The shape of input images (default is (64, 64, 1)).\n",
    "    Returns:\n",
    "    - model (Sequential): The compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layers with pooling.\n",
    "    model.add(Input(shape=input_shape))\n",
    "    if len(input_shape) == 3:\n",
    "        model.add(Conv2D(8, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    # Flatten layer.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layers with Dropout.\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer.\n",
    "    num_classes = 18  # Number of classes (digits 0-9).\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same process for 3 models (not exposure + gray, because it is very bad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback_2 = keras.callbacks.ModelCheckpoint(filepath=\"models/model_v2\", verbose=0, save_best_only=True)\n",
    "\n",
    "model_cnn_2_standard = get_model_cnn_v2(input_shape=(64, 64, 3)) # Because we use a RGB image we precise the 3 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we are < to 1M parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 62, 62, 8)         224       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 31, 31, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 29, 29, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 14, 14, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               401536    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 18)                594       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407650 (1.56 MB)\n",
      "Trainable params: 407650 (1.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_1_standard.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 3.4585 - accuracy: 0.0923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x00000248C029F6A0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\weakref.py\", line 370, in remove\n",
      "    self = selfref()\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x00000248BA304400>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jtrem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\", line 300, in __del__\n",
      "    RUNTIME_FUNCTION_REFS.pop(key)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\model_v2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 180s 21s/step - loss: 3.4585 - accuracy: 0.0923 - val_loss: 2.8779 - val_accuracy: 0.0998\n",
      "Epoch 2/50\n",
      "1/9 [==>...........................] - ETA: 10s - loss: 2.9728 - accuracy: 0.1465"
     ]
    }
   ],
   "source": [
    "samples_weight = compute_sample_weight(\"balanced\", y_train_standard)\n",
    "tensorboard_callback_2 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v2_standard\", histogram_freq=1)\n",
    "model_cnn_2_standard.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on 50 epochs.\n",
    "history_v2_standard = model_cnn_2_standard.fit(\n",
    "    x=x_train_standard,\n",
    "    y=y_train_standard,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_2, tensorboard_callback_2],\n",
    "    validation_data=(x_test_standard, y_test_standard),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now renew the operation with each of the previous image types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 7s 427ms/step - loss: 2.8870 - accuracy: 0.0747 - val_loss: 2.8760 - val_accuracy: 0.1538\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 2.8547 - accuracy: 0.1280 - val_loss: 2.7892 - val_accuracy: 0.2125\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 3s 371ms/step - loss: 2.7870 - accuracy: 0.1697 - val_loss: 2.6686 - val_accuracy: 0.2674\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 2.6706 - accuracy: 0.1958 - val_loss: 2.5030 - val_accuracy: 0.2711\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 2.5351 - accuracy: 0.2089 - val_loss: 2.3527 - val_accuracy: 0.2857\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 2.4323 - accuracy: 0.2414 - val_loss: 2.2201 - val_accuracy: 0.3114\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 2.3481 - accuracy: 0.2533 - val_loss: 2.1441 - val_accuracy: 0.3516\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 3s 276ms/step - loss: 2.2717 - accuracy: 0.2792 - val_loss: 2.0964 - val_accuracy: 0.3544\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 2.2057 - accuracy: 0.2897 - val_loss: 2.0370 - val_accuracy: 0.3965\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 2.1537 - accuracy: 0.3138 - val_loss: 1.9808 - val_accuracy: 0.4304\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 2.1087 - accuracy: 0.3433 - val_loss: 1.9412 - val_accuracy: 0.4304\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 2.0646 - accuracy: 0.3397 - val_loss: 1.9008 - val_accuracy: 0.4414\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 2s 257ms/step - loss: 2.0317 - accuracy: 0.3433 - val_loss: 1.8714 - val_accuracy: 0.4661\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 1.9572 - accuracy: 0.3717 - val_loss: 1.8386 - val_accuracy: 0.4716\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 1.9381 - accuracy: 0.3678 - val_loss: 1.8301 - val_accuracy: 0.4679\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 2s 271ms/step - loss: 1.9111 - accuracy: 0.3830 - val_loss: 1.7813 - val_accuracy: 0.4963\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 2s 218ms/step - loss: 1.8565 - accuracy: 0.4116 - val_loss: 1.7521 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 1.8167 - accuracy: 0.4130 - val_loss: 1.7240 - val_accuracy: 0.5156\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 2s 260ms/step - loss: 1.7770 - accuracy: 0.4187 - val_loss: 1.6856 - val_accuracy: 0.5147\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 1.7416 - accuracy: 0.4450 - val_loss: 1.6804 - val_accuracy: 0.5046\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 2s 246ms/step - loss: 1.7167 - accuracy: 0.4519 - val_loss: 1.6550 - val_accuracy: 0.5147\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 1.6898 - accuracy: 0.4501 - val_loss: 1.6282 - val_accuracy: 0.5385\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 2s 210ms/step - loss: 1.6377 - accuracy: 0.4661 - val_loss: 1.6283 - val_accuracy: 0.5449\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 3s 349ms/step - loss: 1.6179 - accuracy: 0.4702 - val_loss: 1.5732 - val_accuracy: 0.5586\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 2s 238ms/step - loss: 1.5554 - accuracy: 0.4986 - val_loss: 1.5609 - val_accuracy: 0.5357\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 2s 245ms/step - loss: 1.5339 - accuracy: 0.5032 - val_loss: 1.5528 - val_accuracy: 0.5577\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 1.4668 - accuracy: 0.5135 - val_loss: 1.5425 - val_accuracy: 0.5430\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 1.4723 - accuracy: 0.5027 - val_loss: 1.5438 - val_accuracy: 0.5394\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 2s 258ms/step - loss: 1.4151 - accuracy: 0.5204 - val_loss: 1.4789 - val_accuracy: 0.5614\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 1.3700 - accuracy: 0.5339 - val_loss: 1.4568 - val_accuracy: 0.5760\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 1.3439 - accuracy: 0.5442 - val_loss: 1.4446 - val_accuracy: 0.5687\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 2s 257ms/step - loss: 1.3334 - accuracy: 0.5424 - val_loss: 1.4206 - val_accuracy: 0.5824\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 2s 207ms/step - loss: 1.3065 - accuracy: 0.5563 - val_loss: 1.4360 - val_accuracy: 0.5778\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 3s 309ms/step - loss: 1.2900 - accuracy: 0.5598 - val_loss: 1.4368 - val_accuracy: 0.5824\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 2s 270ms/step - loss: 1.2510 - accuracy: 0.5696 - val_loss: 1.4125 - val_accuracy: 0.5824\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 1.2067 - accuracy: 0.5845 - val_loss: 1.3809 - val_accuracy: 0.5971\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 3s 306ms/step - loss: 1.1985 - accuracy: 0.5825 - val_loss: 1.3559 - val_accuracy: 0.6053\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 1.1740 - accuracy: 0.5941 - val_loss: 1.3596 - val_accuracy: 0.6108\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 2s 255ms/step - loss: 1.1380 - accuracy: 0.5985 - val_loss: 1.3520 - val_accuracy: 0.6007\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 1.0958 - accuracy: 0.6173 - val_loss: 1.3191 - val_accuracy: 0.6190\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 2s 272ms/step - loss: 1.1247 - accuracy: 0.6033 - val_loss: 1.3648 - val_accuracy: 0.5980\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 2s 220ms/step - loss: 1.1043 - accuracy: 0.6005 - val_loss: 1.3427 - val_accuracy: 0.6154\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 2s 266ms/step - loss: 1.0462 - accuracy: 0.6264 - val_loss: 1.3120 - val_accuracy: 0.6136\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 1.0320 - accuracy: 0.6349 - val_loss: 1.3124 - val_accuracy: 0.6218\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 1.0054 - accuracy: 0.6351 - val_loss: 1.3008 - val_accuracy: 0.6181\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 0.9785 - accuracy: 0.6493 - val_loss: 1.2891 - val_accuracy: 0.6282\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.9339 - accuracy: 0.6555 - val_loss: 1.2814 - val_accuracy: 0.6227\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 2s 275ms/step - loss: 0.9175 - accuracy: 0.6677 - val_loss: 1.2720 - val_accuracy: 0.6300\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 254ms/step - loss: 0.9101 - accuracy: 0.6622 - val_loss: 1.2647 - val_accuracy: 0.6273\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 2s 251ms/step - loss: 0.8861 - accuracy: 0.6688 - val_loss: 1.2763 - val_accuracy: 0.6291\n"
     ]
    }
   ],
   "source": [
    "# Gray scale.\n",
    "model_cnn_2_gray = get_model_cnn_v2(input_shape=(64, 64, 1))\n",
    "tensorboard_callback_2 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v2_gray\", histogram_freq=1)\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_gray)\n",
    "model_cnn_2_gray.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v2_gray = model_cnn_2_gray.fit(\n",
    "    x=x_train_gray,\n",
    "    y=y_train_gray,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_2, tensorboard_callback_2],\n",
    "    validation_data=(x_test_gray, y_test_gray),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 21s 1s/step - loss: 2.8904 - accuracy: 0.0822 - val_loss: 2.8881 - val_accuracy: 0.0852\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 4s 434ms/step - loss: 2.8889 - accuracy: 0.0902 - val_loss: 2.8838 - val_accuracy: 0.0943\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 4s 403ms/step - loss: 2.8834 - accuracy: 0.0978 - val_loss: 2.8655 - val_accuracy: 0.0916\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 4s 488ms/step - loss: 2.8730 - accuracy: 0.1054 - val_loss: 2.8363 - val_accuracy: 0.1136\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 4s 411ms/step - loss: 2.8479 - accuracy: 0.1326 - val_loss: 2.7986 - val_accuracy: 0.1200\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 2.8020 - accuracy: 0.1422 - val_loss: 2.7299 - val_accuracy: 0.1273\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 4s 416ms/step - loss: 2.7260 - accuracy: 0.1427 - val_loss: 2.6005 - val_accuracy: 0.1474\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 4s 393ms/step - loss: 2.6351 - accuracy: 0.1619 - val_loss: 2.5001 - val_accuracy: 0.1804\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 4s 437ms/step - loss: 2.5601 - accuracy: 0.1874 - val_loss: 2.3776 - val_accuracy: 0.2592\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 2.4790 - accuracy: 0.2151 - val_loss: 2.2614 - val_accuracy: 0.3022\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 4s 399ms/step - loss: 2.4199 - accuracy: 0.2366 - val_loss: 2.1919 - val_accuracy: 0.3278\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 4s 436ms/step - loss: 2.3548 - accuracy: 0.2641 - val_loss: 2.1269 - val_accuracy: 0.3434\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 4s 435ms/step - loss: 2.3384 - accuracy: 0.2517 - val_loss: 2.0681 - val_accuracy: 0.3443\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 4s 456ms/step - loss: 2.2931 - accuracy: 0.2732 - val_loss: 2.0852 - val_accuracy: 0.3526\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 4s 489ms/step - loss: 2.2685 - accuracy: 0.2753 - val_loss: 2.0041 - val_accuracy: 0.3690\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 4s 380ms/step - loss: 2.2382 - accuracy: 0.2884 - val_loss: 1.9873 - val_accuracy: 0.3837\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 4s 431ms/step - loss: 2.2241 - accuracy: 0.2904 - val_loss: 1.9796 - val_accuracy: 0.3846\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 3s 385ms/step - loss: 2.1791 - accuracy: 0.3010 - val_loss: 1.9262 - val_accuracy: 0.3984\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 4s 433ms/step - loss: 2.1592 - accuracy: 0.3087 - val_loss: 1.9141 - val_accuracy: 0.4011\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 4s 389ms/step - loss: 2.1527 - accuracy: 0.3142 - val_loss: 1.8981 - val_accuracy: 0.3956\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 3s 391ms/step - loss: 2.1340 - accuracy: 0.3181 - val_loss: 1.8859 - val_accuracy: 0.4029\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 4s 448ms/step - loss: 2.1168 - accuracy: 0.3191 - val_loss: 1.8849 - val_accuracy: 0.4139\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 4s 425ms/step - loss: 2.1009 - accuracy: 0.3241 - val_loss: 1.8459 - val_accuracy: 0.4167\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 4s 398ms/step - loss: 2.0917 - accuracy: 0.3294 - val_loss: 1.9053 - val_accuracy: 0.4029\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 5s 581ms/step - loss: 2.0787 - accuracy: 0.3262 - val_loss: 1.8433 - val_accuracy: 0.4295\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 4s 501ms/step - loss: 2.0526 - accuracy: 0.3507 - val_loss: 1.8156 - val_accuracy: 0.4313\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 5s 624ms/step - loss: 2.0550 - accuracy: 0.3436 - val_loss: 1.8335 - val_accuracy: 0.4286\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 4s 468ms/step - loss: 2.0235 - accuracy: 0.3481 - val_loss: 1.8011 - val_accuracy: 0.4524\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 4s 436ms/step - loss: 1.9994 - accuracy: 0.3580 - val_loss: 1.7826 - val_accuracy: 0.4441\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 4s 408ms/step - loss: 2.0040 - accuracy: 0.3520 - val_loss: 1.7874 - val_accuracy: 0.4386\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 1.9967 - accuracy: 0.3685 - val_loss: 1.7809 - val_accuracy: 0.4597\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 3s 398ms/step - loss: 1.9649 - accuracy: 0.3713 - val_loss: 1.7724 - val_accuracy: 0.4679\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 3s 361ms/step - loss: 1.9626 - accuracy: 0.3683 - val_loss: 1.7536 - val_accuracy: 0.4606\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 5s 627ms/step - loss: 1.9402 - accuracy: 0.3864 - val_loss: 1.7453 - val_accuracy: 0.4634\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 4s 467ms/step - loss: 1.9366 - accuracy: 0.3830 - val_loss: 1.7533 - val_accuracy: 0.4734\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 5s 537ms/step - loss: 1.9483 - accuracy: 0.3816 - val_loss: 1.7311 - val_accuracy: 0.4753\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 4s 333ms/step - loss: 1.9133 - accuracy: 0.3859 - val_loss: 1.7178 - val_accuracy: 0.4780\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 4s 427ms/step - loss: 1.9077 - accuracy: 0.3765 - val_loss: 1.7594 - val_accuracy: 0.4799\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 4s 406ms/step - loss: 1.9120 - accuracy: 0.3830 - val_loss: 1.7039 - val_accuracy: 0.4780\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 4s 435ms/step - loss: 1.9213 - accuracy: 0.3839 - val_loss: 1.7103 - val_accuracy: 0.4890\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 4s 418ms/step - loss: 1.9254 - accuracy: 0.3820 - val_loss: 1.7197 - val_accuracy: 0.4881\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 4s 457ms/step - loss: 1.8894 - accuracy: 0.3859 - val_loss: 1.6795 - val_accuracy: 0.4918\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 3s 366ms/step - loss: 1.8835 - accuracy: 0.3969 - val_loss: 1.6855 - val_accuracy: 0.4918\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 4s 409ms/step - loss: 1.8536 - accuracy: 0.4082 - val_loss: 1.6749 - val_accuracy: 0.4918\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 3s 345ms/step - loss: 1.8357 - accuracy: 0.4063 - val_loss: 1.6755 - val_accuracy: 0.4890\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 3s 378ms/step - loss: 1.8675 - accuracy: 0.4052 - val_loss: 1.6548 - val_accuracy: 0.5101\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 3s 372ms/step - loss: 1.8337 - accuracy: 0.4141 - val_loss: 1.6625 - val_accuracy: 0.4890\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 3s 290ms/step - loss: 1.8437 - accuracy: 0.4061 - val_loss: 1.6614 - val_accuracy: 0.5046\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 2s 271ms/step - loss: 1.8317 - accuracy: 0.4214 - val_loss: 1.6591 - val_accuracy: 0.5082\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 3s 350ms/step - loss: 1.8059 - accuracy: 0.4217 - val_loss: 1.6393 - val_accuracy: 0.4954\n"
     ]
    }
   ],
   "source": [
    "# Exposure.\n",
    "model_cnn_2_exposure = get_model_cnn_v2(input_shape=(64, 64, 3))\n",
    "tensorboard_callback_2 = keras.callbacks.TensorBoard(log_dir=\"logs/cnn_v2_exposure\", histogram_freq=1)\n",
    "samples_weight = compute_sample_weight(\"balanced\", y_train_exposure)\n",
    "model_cnn_2_exposure.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_v2_exposure = model_cnn_2_exposure.fit(\n",
    "    x=x_train_exposure,\n",
    "    y=y_train_exposure,\n",
    "    batch_size=512,\n",
    "    epochs=50,\t\n",
    "    callbacks=[save_callback_2, tensorboard_callback_2],\n",
    "    validation_data=(x_test_exposure, y_test_exposure),\n",
    "    sample_weight=samples_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the differences (and check tensorboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy for the models with convolutional layers.\n",
    "plt.plot(history_v2_standard.history['accuracy'], label='Train Standard')\n",
    "plt.plot(history_v2_standard.history['val_accuracy'], label='Validation Standard')\n",
    "\n",
    "plt.plot(history_v2_gray.history['accuracy'], label='Train Gray')\n",
    "plt.plot(history_v2_gray.history['val_accuracy'], label='Validation Gray')\n",
    "\n",
    "plt.plot(history_v2_exposure.history['accuracy'], label='Train Exposure')\n",
    "plt.plot(history_v2_exposure.history['val_accuracy'], label='Validation Exposure')\n",
    "\n",
    "plt.title('Training and Validation Accuracy Comparison Between Models')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
